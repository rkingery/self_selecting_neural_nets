{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import lfilter\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from ss_perf_utils import *\n",
    "\n",
    "np.random.seed(2)\n",
    "torch.manual_seed(2)\n",
    "\n",
    "global device,dtype\n",
    "device = torch.device('cuda:0')\n",
    "#device = torch.device('cpu')\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pytorch(X,y,layer_dims,num_iters,lr=0.01,add_del=False):\n",
    "    sigmoid = lambda z : 1./(1+torch.exp(-z))\n",
    "    \n",
    "    din,dh,dout = tuple(layer_dims)\n",
    "    m = X.shape[1]\n",
    "    delta,prob,epsilon,max_hidden_size,tau = init_add_del()\n",
    "    losses = []\n",
    "    num_neurons = []\n",
    "    \n",
    "    W1 = torch.randn(dh, din, dtype=dtype, requires_grad=False, device=device)\n",
    "    b1 = torch.randn(dh, 1, dtype=dtype, requires_grad=False, device=device)\n",
    "    W2 = torch.randn(dout, dh, dtype=dtype, requires_grad=False, device=device)\n",
    "    b2 = torch.randn(dout, 1, dtype=dtype, requires_grad=False, device=device)\n",
    "    \n",
    "    for t in range(num_iters):\n",
    "        # Forwardprop\n",
    "        Z1 = torch.mm(W1,X)+b1\n",
    "        A = Z1.clamp(min=0) # relu\n",
    "        Z2 = torch.mm(W2,A)+b2\n",
    "        yhat = sigmoid(Z2).clamp(1e-6,1.-1e-6)\n",
    "    \n",
    "        criterion = nn.BCELoss()\n",
    "        loss = criterion(yhat,y)\n",
    "        loss = loss.squeeze_().item()\n",
    "        losses.append(loss)\n",
    "    \n",
    "        # Backprop\n",
    "        dyhat = -(torch.div(y,yhat) - torch.div(1-y, 1-yhat))\n",
    "        dZ2 = dyhat*sigmoid(Z2)*(1-sigmoid(Z2))\n",
    "        dW2 = 1./m*torch.mm(dZ2,A.t())\n",
    "        db2 = 1./m*torch.sum(dZ2,1,keepdim=True)\n",
    "        dA = torch.mm(W2.t(),dZ2)\n",
    "        dZ1 = dA\n",
    "        dZ1[Z1 < 0] = 0\n",
    "        dW1 = 1./m*torch.mm(dZ1,X.t())\n",
    "        db1 = 1./m*torch.sum(dZ1,1,keepdim=True)\n",
    "    \n",
    "        # gradient descent\n",
    "        W1 -= lr*dW1\n",
    "        b1 -= lr*db1\n",
    "        W2 -= lr*dW2\n",
    "        b2 -= lr*db2\n",
    "\n",
    "        if add_del and t>tau:\n",
    "            W1,b1,W2,b2 = delete_neurons_pytorch(W1,b1,W2,b2,delta,prob)\n",
    "            W1,b1,W2,b2 = add_neurons_pytorch(W1,b1,W2,b2,losses,epsilon,delta,max_hidden_size,tau,prob,device)\n",
    "        num_neurons.append(b1.shape[0])\n",
    "\n",
    "        if t % max(1,num_iters // 20) == 0:\n",
    "            print('loss after iteration %i: %f' % (t, losses[-1]))\n",
    "            if add_del:\n",
    "                print('# neurons after iteration %i: %d' % (t, num_neurons[-1]))\n",
    "    \n",
    "    return losses,num_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_hparams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4549a90e5193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlayer_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_hparams' is not defined"
     ]
    }
   ],
   "source": [
    "num_iters,num_samples,num_features,num_hidden,num_classes,lr = init_hparams()\n",
    "layer_dims = [num_features,num_hidden,num_classes]\n",
    "\n",
    "X,y,x1,x2 = gen_data(samples=num_samples,var=0.01)\n",
    "X = torch.tensor(X,device=device,dtype=dtype).t()\n",
    "y = torch.tensor(y,device=device,dtype=dtype).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tin = time.clock()\n",
    "losses,num_neurons = train_pytorch(X,y,layer_dims,num_iters,lr=lr,add_del=True)\n",
    "tout = time.clock()\n",
    "tdiff = tout-tin\n",
    "print('time = %f' % tdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.array(losses)\n",
    "filt_neurons = lfilter([1.0/50]*50,1,num_neurons)\n",
    "filt_neurons[filt_neurons<1] = num_hidden\n",
    "\n",
    "plt.plot(losses,color='blue')\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(filt_neurons,color='green')\n",
    "plt.title('# Neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
